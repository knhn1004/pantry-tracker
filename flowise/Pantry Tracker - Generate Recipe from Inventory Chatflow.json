{
	"nodes": [
		{
			"id": "promptTemplate_0",
			"position": {
				"x": 108.34787989234309,
				"y": 687.5434128931229
			},
			"type": "customNode",
			"data": {
				"id": "promptTemplate_0",
				"label": "Prompt Template",
				"version": 1,
				"name": "promptTemplate",
				"type": "PromptTemplate",
				"baseClasses": [
					"PromptTemplate",
					"BaseStringPromptTemplate",
					"BasePromptTemplate",
					"Runnable"
				],
				"category": "Prompts",
				"description": "Schema to represent a basic prompt for an LLM",
				"inputParams": [
					{
						"label": "Template",
						"name": "template",
						"type": "string",
						"rows": 4,
						"placeholder": "What is a good name for a company that makes {product}?",
						"id": "promptTemplate_0-input-template-string"
					},
					{
						"label": "Format Prompt Values",
						"name": "promptValues",
						"type": "json",
						"optional": true,
						"acceptVariable": true,
						"list": true,
						"id": "promptTemplate_0-input-promptValues-json"
					}
				],
				"inputAnchors": [],
				"inputs": {
					"template": "You are an experienced home chef.\nUse the following inventory to create a recipe for a meal. Prioritize items closer to expiry. Serving for 1-3 people.\nInventory: {inventory}",
					"promptValues": "{\"inventory\":\"{{question}}\"}"
				},
				"outputAnchors": [
					{
						"id": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
						"name": "promptTemplate",
						"label": "PromptTemplate",
						"description": "Schema to represent a basic prompt for an LLM",
						"type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable"
					}
				],
				"outputs": {},
				"selected": false
			},
			"width": 300,
			"height": 513,
			"selected": false,
			"positionAbsolute": {
				"x": 108.34787989234309,
				"y": 687.5434128931229
			},
			"dragging": false
		},
		{
			"id": "llmChain_0",
			"position": {
				"x": 614.2591106523629,
				"y": 711.1572175816627
			},
			"type": "customNode",
			"data": {
				"id": "llmChain_0",
				"label": "LLM Chain",
				"version": 3,
				"name": "llmChain",
				"type": "LLMChain",
				"baseClasses": ["LLMChain", "BaseChain", "Runnable"],
				"category": "Chains",
				"description": "Chain to run queries against LLMs",
				"inputParams": [
					{
						"label": "Chain Name",
						"name": "chainName",
						"type": "string",
						"placeholder": "Name Your Chain",
						"optional": true,
						"id": "llmChain_0-input-chainName-string"
					}
				],
				"inputAnchors": [
					{
						"label": "Language Model",
						"name": "model",
						"type": "BaseLanguageModel",
						"id": "llmChain_0-input-model-BaseLanguageModel"
					},
					{
						"label": "Prompt",
						"name": "prompt",
						"type": "BasePromptTemplate",
						"id": "llmChain_0-input-prompt-BasePromptTemplate"
					},
					{
						"label": "Output Parser",
						"name": "outputParser",
						"type": "BaseLLMOutputParser",
						"optional": true,
						"id": "llmChain_0-input-outputParser-BaseLLMOutputParser"
					},
					{
						"label": "Input Moderation",
						"description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
						"name": "inputModeration",
						"type": "Moderation",
						"optional": true,
						"list": true,
						"id": "llmChain_0-input-inputModeration-Moderation"
					}
				],
				"inputs": {
					"model": "{{chatOpenAI_0.data.instance}}",
					"prompt": "{{promptTemplate_0.data.instance}}",
					"outputParser": "{{structuredOutputParser_0.data.instance}}",
					"inputModeration": "",
					"chainName": "home chef"
				},
				"outputAnchors": [
					{
						"name": "output",
						"label": "Output",
						"type": "options",
						"description": "",
						"options": [
							{
								"id": "llmChain_0-output-llmChain-LLMChain|BaseChain|Runnable",
								"name": "llmChain",
								"label": "LLM Chain",
								"description": "",
								"type": "LLMChain | BaseChain | Runnable"
							},
							{
								"id": "llmChain_0-output-outputPrediction-string|json",
								"name": "outputPrediction",
								"label": "Output Prediction",
								"description": "",
								"type": "string | json"
							}
						],
						"default": "llmChain"
					}
				],
				"outputs": {
					"output": "llmChain"
				},
				"selected": false
			},
			"width": 300,
			"height": 508,
			"selected": false,
			"positionAbsolute": {
				"x": 614.2591106523629,
				"y": 711.1572175816627
			},
			"dragging": false
		},
		{
			"id": "chatOpenAI_0",
			"position": {
				"x": 113.00301430248933,
				"y": -84.941086403104
			},
			"type": "customNode",
			"data": {
				"id": "chatOpenAI_0",
				"label": "ChatOpenAI",
				"version": 6,
				"name": "chatOpenAI",
				"type": "ChatOpenAI",
				"baseClasses": [
					"ChatOpenAI",
					"BaseChatModel",
					"BaseLanguageModel",
					"Runnable"
				],
				"category": "Chat Models",
				"description": "Wrapper around OpenAI large language models that use the Chat endpoint",
				"inputParams": [
					{
						"label": "Connect Credential",
						"name": "credential",
						"type": "credential",
						"credentialNames": ["openAIApi"],
						"id": "chatOpenAI_0-input-credential-credential"
					},
					{
						"label": "Model Name",
						"name": "modelName",
						"type": "asyncOptions",
						"loadMethod": "listModels",
						"default": "gpt-3.5-turbo",
						"id": "chatOpenAI_0-input-modelName-asyncOptions"
					},
					{
						"label": "Temperature",
						"name": "temperature",
						"type": "number",
						"step": 0.1,
						"default": 0.9,
						"optional": true,
						"id": "chatOpenAI_0-input-temperature-number"
					},
					{
						"label": "Max Tokens",
						"name": "maxTokens",
						"type": "number",
						"step": 1,
						"optional": true,
						"additionalParams": true,
						"id": "chatOpenAI_0-input-maxTokens-number"
					},
					{
						"label": "Top Probability",
						"name": "topP",
						"type": "number",
						"step": 0.1,
						"optional": true,
						"additionalParams": true,
						"id": "chatOpenAI_0-input-topP-number"
					},
					{
						"label": "Frequency Penalty",
						"name": "frequencyPenalty",
						"type": "number",
						"step": 0.1,
						"optional": true,
						"additionalParams": true,
						"id": "chatOpenAI_0-input-frequencyPenalty-number"
					},
					{
						"label": "Presence Penalty",
						"name": "presencePenalty",
						"type": "number",
						"step": 0.1,
						"optional": true,
						"additionalParams": true,
						"id": "chatOpenAI_0-input-presencePenalty-number"
					},
					{
						"label": "Timeout",
						"name": "timeout",
						"type": "number",
						"step": 1,
						"optional": true,
						"additionalParams": true,
						"id": "chatOpenAI_0-input-timeout-number"
					},
					{
						"label": "BasePath",
						"name": "basepath",
						"type": "string",
						"optional": true,
						"additionalParams": true,
						"id": "chatOpenAI_0-input-basepath-string"
					},
					{
						"label": "BaseOptions",
						"name": "baseOptions",
						"type": "json",
						"optional": true,
						"additionalParams": true,
						"id": "chatOpenAI_0-input-baseOptions-json"
					},
					{
						"label": "Allow Image Uploads",
						"name": "allowImageUploads",
						"type": "boolean",
						"description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
						"default": false,
						"optional": true,
						"id": "chatOpenAI_0-input-allowImageUploads-boolean"
					},
					{
						"label": "Image Resolution",
						"description": "This parameter controls the resolution in which the model views the image.",
						"name": "imageResolution",
						"type": "options",
						"options": [
							{
								"label": "Low",
								"name": "low"
							},
							{
								"label": "High",
								"name": "high"
							},
							{
								"label": "Auto",
								"name": "auto"
							}
						],
						"default": "low",
						"optional": false,
						"additionalParams": true,
						"id": "chatOpenAI_0-input-imageResolution-options"
					}
				],
				"inputAnchors": [
					{
						"label": "Cache",
						"name": "cache",
						"type": "BaseCache",
						"optional": true,
						"id": "chatOpenAI_0-input-cache-BaseCache"
					}
				],
				"inputs": {
					"cache": "",
					"modelName": "gpt-4-turbo",
					"temperature": 0.9,
					"maxTokens": "",
					"topP": "",
					"frequencyPenalty": "",
					"presencePenalty": "",
					"timeout": "",
					"basepath": "",
					"baseOptions": "",
					"allowImageUploads": "",
					"imageResolution": "low"
				},
				"outputAnchors": [
					{
						"id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
						"name": "chatOpenAI",
						"label": "ChatOpenAI",
						"description": "Wrapper around OpenAI large language models that use the Chat endpoint",
						"type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
					}
				],
				"outputs": {},
				"selected": false
			},
			"width": 300,
			"height": 670,
			"selected": false,
			"positionAbsolute": {
				"x": 113.00301430248933,
				"y": -84.941086403104
			},
			"dragging": false
		},
		{
			"id": "structuredOutputParser_0",
			"position": {
				"x": 115.17090023248528,
				"y": 1253.823327084264
			},
			"type": "customNode",
			"data": {
				"id": "structuredOutputParser_0",
				"label": "Structured Output Parser",
				"version": 1,
				"name": "structuredOutputParser",
				"type": "StructuredOutputParser",
				"baseClasses": [
					"StructuredOutputParser",
					"BaseLLMOutputParser",
					"Runnable"
				],
				"category": "Output Parsers",
				"description": "Parse the output of an LLM call into a given (JSON) structure.",
				"inputParams": [
					{
						"label": "Autofix",
						"name": "autofixParser",
						"type": "boolean",
						"optional": true,
						"description": "In the event that the first call fails, will make another call to the model to fix any errors.",
						"id": "structuredOutputParser_0-input-autofixParser-boolean"
					},
					{
						"label": "JSON Structure",
						"name": "jsonStructure",
						"type": "datagrid",
						"description": "JSON structure for LLM to return",
						"datagrid": [
							{
								"field": "property",
								"headerName": "Property",
								"editable": true
							},
							{
								"field": "type",
								"headerName": "Type",
								"type": "singleSelect",
								"valueOptions": ["string", "number", "boolean"],
								"editable": true
							},
							{
								"field": "description",
								"headerName": "Description",
								"editable": true,
								"flex": 1
							}
						],
						"default": [
							{
								"property": "answer",
								"type": "string",
								"description": "answer to the user's question"
							},
							{
								"property": "source",
								"type": "string",
								"description": "sources used to answer the question, should be websites"
							}
						],
						"additionalParams": true,
						"id": "structuredOutputParser_0-input-jsonStructure-datagrid"
					}
				],
				"inputAnchors": [],
				"inputs": {
					"autofixParser": true,
					"jsonStructure": "[{\"property\":\"steps\",\"type\":\"string\",\"description\":\"markdown of steps\",\"actions\":\"\",\"id\":0},{\"property\":\"ingredients\",\"type\":\"string\",\"description\":\"JSON array of ingredients with id and name, quantity, and unit_id. Quantity is strictly a number, no units included)\",\"actions\":\"\",\"id\":1},{\"property\":\"recipeName\",\"type\":\"string\",\"description\":\"recipe name\",\"actions\":\"\",\"id\":2},{\"property\":\"serving\",\"type\":\"number\",\"description\":\"serving size (how many people)\",\"actions\":\"\",\"id\":3},{\"property\":\"prepTime\",\"type\":\"number\",\"description\":\"time for prepping this recipe in minutes\",\"actions\":\"\",\"id\":4},{\"property\":\"cookTime\",\"type\":\"number\",\"description\":\"time for cooking this recipe in minutes\",\"actions\":\"\",\"id\":5},{\"property\":\"description\",\"type\":\"string\",\"description\":\"short description of the recipe in a sentence\",\"actions\":\"\",\"id\":6}]"
				},
				"outputAnchors": [
					{
						"id": "structuredOutputParser_0-output-structuredOutputParser-StructuredOutputParser|BaseLLMOutputParser|Runnable",
						"name": "structuredOutputParser",
						"label": "StructuredOutputParser",
						"description": "Parse the output of an LLM call into a given (JSON) structure.",
						"type": "StructuredOutputParser | BaseLLMOutputParser | Runnable"
					}
				],
				"outputs": {},
				"selected": false
			},
			"width": 300,
			"height": 329,
			"selected": false,
			"positionAbsolute": {
				"x": 115.17090023248528,
				"y": 1253.823327084264
			},
			"dragging": false
		}
	],
	"edges": [
		{
			"source": "promptTemplate_0",
			"sourceHandle": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
			"target": "llmChain_0",
			"targetHandle": "llmChain_0-input-prompt-BasePromptTemplate",
			"type": "buttonedge",
			"id": "promptTemplate_0-promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable-llmChain_0-llmChain_0-input-prompt-BasePromptTemplate"
		},
		{
			"source": "chatOpenAI_0",
			"sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
			"target": "llmChain_0",
			"targetHandle": "llmChain_0-input-model-BaseLanguageModel",
			"type": "buttonedge",
			"id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-llmChain_0-llmChain_0-input-model-BaseLanguageModel"
		},
		{
			"source": "structuredOutputParser_0",
			"sourceHandle": "structuredOutputParser_0-output-structuredOutputParser-StructuredOutputParser|BaseLLMOutputParser|Runnable",
			"target": "llmChain_0",
			"targetHandle": "llmChain_0-input-outputParser-BaseLLMOutputParser",
			"type": "buttonedge",
			"id": "structuredOutputParser_0-structuredOutputParser_0-output-structuredOutputParser-StructuredOutputParser|BaseLLMOutputParser|Runnable-llmChain_0-llmChain_0-input-outputParser-BaseLLMOutputParser"
		}
	]
}
